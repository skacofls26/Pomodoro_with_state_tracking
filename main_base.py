'''
main.py
    User Interface êµ¬í˜„ ë¡œì§
    ì‹¤í–‰ ëª…ë ¹ì–´: streamlit run main_base.py
'''
import streamlit as st
import cv2
import time
import pandas as pd
import altair as alt
from datetime import datetime
from config import Pose, FaceMesh
from gaze_estimation import is_focused
from drowsy_estimation import is_drowsy

st.set_page_config(page_title="í•™ìŠµ ë³´ì¡° ì• í”Œë¦¬ì¼€ì´ì…˜", layout="centered")
st.title("\U0001f9e0 í•™ìŠµ ë³´ì¡° ì• í”Œë¦¬ì¼€ì´ì…˜")

# ========================= ìƒíƒœ ì´ˆê¸°í™” =========================
if "cap" not in st.session_state:
    st.session_state.cap = None
if "running" not in st.session_state:
    st.session_state.running = False
if "data" not in st.session_state:
    st.session_state.data = {
        "time": [], "focus": [], "state": []
    }
if "current_state" not in st.session_state:
    st.session_state.current_state = "í™”ë©´ ë¹„ì§‘ì¤‘ ìƒíƒœ"
if "focus_timer" not in st.session_state:
    st.session_state.focus_timer = None
if "snapshot_image" not in st.session_state:
    st.session_state.snapshot_image = None
if "last_snapshot_time" not in st.session_state:
    st.session_state.last_snapshot_time = 0
if "drowsy" not in st.session_state:
    st.session_state.drowsy = False
if "eye_closed_start" not in st.session_state:
    st.session_state.eye_closed_start = None
if "last_known_state_when_no_ear" not in st.session_state:
    st.session_state.last_known_state_when_no_ear = None
if "state_locked_until_ear_detected" not in st.session_state:
    st.session_state.state_locked_until_ear_detected = False
if "pose_history" not in st.session_state:
    st.session_state.pose_history = []  # [(time, left_ear_y, right_ear_y)]

# âœ… ìŠ¤íŠ¸ë¦¬ë° ë²„íŠ¼
with st.container():
    col_btn = st.columns([1])[0]
    toggle_label = "â¹ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€" if st.session_state.running else "â–¶ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘"
    if col_btn.button(toggle_label, key="stream_button"):
        if st.session_state.running:
            if st.session_state.cap:
                st.session_state.cap.release()
                st.session_state.cap = None
            st.session_state.running = False
            st.rerun()
        else:
            st.session_state.cap = cv2.VideoCapture(0)
            if st.session_state.cap.isOpened():
                st.session_state.running = True
                st.session_state.start_time = time.monotonic()
                st.session_state.focus_timer = None
                st.session_state.last_remain_sec = None
                st.session_state.drowsy = False
                st.session_state.eye_closed_start = None
                st.session_state.last_known_state_when_no_ear = None
                st.session_state.state_locked_until_ear_detected = False
                st.session_state.pose_history = []
            else:
                st.error("âŒ ì¹´ë©”ë¼ ì—´ê¸°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

# ========================= ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° =========================
if st.session_state.running and st.session_state.cap:
    ret, frame = st.session_state.cap.read()
    if not ret:
        st.warning("âŒ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        now = time.monotonic() 
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        pose_results = Pose.process(rgb)
        face_results = FaceMesh.process(rgb)
        h, w = frame.shape[:2]

        theta, phi, focused = is_focused(frame)        
        ear, drowsy = is_drowsy(face_results.multi_face_landmarks, h, w)

        timestamp = datetime.now()

        # ================= Pose íˆìŠ¤í† ë¦¬ ëˆ„ì  =================
        if st.session_state.current_state not in ["ìˆ˜ë©´ ìƒíƒœ", "ì™¸ì¶œ ìƒíƒœ"]: 
            if pose_results and pose_results.pose_landmarks:
                left_ear = pose_results.pose_landmarks.landmark[7]
                right_ear = pose_results.pose_landmarks.landmark[8]
                y_vals = []
                if left_ear.visibility > 0.5:
                    y_vals.append(left_ear.y * h)
                if right_ear.visibility > 0.5:
                    y_vals.append(right_ear.y * h)
                if y_vals:
                    avg_y = sum(y_vals) / len(y_vals)
                    st.session_state.pose_history.append((now, avg_y))
                    st.session_state.pose_history = [
                        (t, y) for (t, y) in st.session_state.pose_history if now - t <= 3.0
                    ]

        # ================= ìƒíƒœ íŒë³„ =================
        new_state = None

        # â”€â”€â”€ 0) EAR ê°ì§€ ì‹œ ì´ˆê¸°í™” â”€â”€â”€
        if ear is not None:
            st.session_state.state_locked_until_ear_detected = False
            st.session_state.last_known_state_when_no_ear = None

        if st.session_state.state_locked_until_ear_detected:  # ìˆ˜ë©´/ì™¸ì¶œ íŒë‹¨í–ˆìœ¼ë©´ ìœ ì§€
            new_state = st.session_state.last_known_state_when_no_ear
        else:
            # â”€â”€â”€ 1) ì¡¸ìŒ íŒë‹¨ â”€â”€â”€
            if drowsy:                                
                new_state = "ì¡¸ìŒ ìƒíƒœ"  # drowsyëŠ” ì§‘ì¤‘ ìƒíƒœì—ì„œë„ ë‚˜íƒ€ë‚˜ë¯€ë¡œ ë¨¼ì € íŒë‹¨
            
            # â”€â”€â”€ 2) í™”ë©´ ì§‘ì¤‘ â”€â”€â”€
            elif focused:
                new_state = "í™”ë©´ ì§‘ì¤‘ ìƒíƒœ"
                st.session_state.focus_timer = None 

            # â”€â”€â”€ 3) í™”ë©´ ë¹„ì§‘ì¤‘ â”€â”€â”€
            else:

                # â”€â”€â”€ 3-1) EAR ë¯¸ê°ì§€ â”€â”€â”€
                if ear is None:
                    ear_y_values = [y for (_, y) in st.session_state.pose_history]
                    if len(ear_y_values) < 10:   
		                # ìµœê·¼ 3ì´ˆ ê¸°ë¡ì—ì„œ ë°ì´í„° ë¶€ì¡± 
                        new_state = st.session_state.current_state
                    else:
                        # 1íšŒ íŒë‹¨
                        y_diff = max(ear_y_values) - min(ear_y_values)
                        if y_diff >= 15:
                            # max(y_values)ê°€ min(y_values)ë³´ë‹¤ ë‚˜ì¤‘ì´ë©´ ìˆ˜ë©´, ë¨¼ì €ë©´ ì™¸ì¶œ
                            max_y_time = next(t for (t, y) in st.session_state.pose_history if y == max(ear_y_values))
                            min_y_time = next(t for (t, y) in st.session_state.pose_history if y == min(ear_y_values))
                            if max_y_time < min_y_time:
                                result = "ì™¸ì¶œ ìƒíƒœ"
                            else:
                                result = "ìˆ˜ë©´ ìƒíƒœ"
                        else:
                            # ë³„ ì°¨ì´ ì•ˆë‚˜ë©´ ë¹„ì§‘ì¤‘
                            result = "í™”ë©´ ë¹„ì§‘ì¤‘ ìƒíƒœ"
                            
                        # EAR ì¬ê°ì§€ ì „ê¹Œì§€ ì ê¸ˆ 
                        st.session_state.last_known_state_when_no_ear = result
                        st.session_state.state_locked_until_ear_detected = True
                        new_state = result
                # â”€â”€â”€ 3-2) EAR ê°ì§€ â”€â”€â”€
                else:
                    new_state = "í™”ë©´ ë¹„ì§‘ì¤‘ ìƒíƒœ"

        # â”€â”€â”€ 4) í˜„ì¬ ìƒíƒœ ì €ì¥ â”€â”€â”€
        st.session_state.current_state = new_state

        # í˜„ì¬ ìƒíƒœ í‘œì‹œ
        with st.container():
            state_text = st.session_state.current_state
            if "ì§‘ì¤‘" in state_text and "ë¹„ì§‘ì¤‘" not in state_text:
                st.success(f"ğŸ§   {state_text}")
            else:
                st.error(f"ğŸ§   {state_text}")

        # ë°ì´í„° ì €ì¥
        st.session_state.data["time"].append(timestamp)
        st.session_state.data["focus"].append("Focused" if focused else "Not Focused")
        st.session_state.data["stte"].append(st.session_state.current_state)

        # ìë™ ìŠ¤ëƒ…ìƒ·
        if now - st.session_state.last_snapshot_time > 10:
            st.session_state.snapshot_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            st.session_state.last_snapshot_time = now

        # ì‹œê°í™”: ìŠ¤ëƒ…ìƒ· + ì§‘ì¤‘ ìƒíƒœ
        show_snapshot = (
            st.session_state.snapshot_image is not None and
            time.monotonic() - st.session_state.last_snapshot_time < 12
        )

        if show_snapshot or st.session_state.data["time"]:
            with st.container():
                col_snap, col_chart = st.columns([1, 2])

                with col_snap:
                    if show_snapshot:
                        ts_txt = datetime.fromtimestamp(
                            st.session_state.last_snapshot_time
                        ).strftime('%H:%M:%S')
                        st.subheader(f"ğŸ“¸ {ts_txt}")
                        st.image(st.session_state.snapshot_image, width=200)

                with col_chart:
                    df = pd.DataFrame({
                        "Time": st.session_state.data["time"],
                        "State": st.session_state.data["state"]
                    })
                    latest_time = df["Time"].max()
                    df_recent = df[df["Time"] >= latest_time - pd.Timedelta(seconds=30)]
                    df_recent["State_Visual"] = df_recent["State"].replace({
                        "ìˆ˜ë©´ ìƒíƒœ": "ì¡¸ìŒ ìƒíƒœ"
                    })
                    
                    st.subheader("ğŸ“‰ ìƒíƒœ ëª¨ë‹ˆí„°ë§")
                    focus_chart = alt.Chart(df_recent).mark_circle(size=60).encode(
                        x=alt.X("Time:T", title="Time"),
                        y=alt.Y("State", title="State"),
                        color=alt.Color("State_Visual", legend=None, scale=alt.Scale(
                            domain=[
                                "í™”ë©´ ì§‘ì¤‘ ìƒíƒœ",
                                "ì¡¸ìŒ ìƒíƒœ",
                                "ì™¸ì¶œ ìƒíƒœ",
                                "í™”ë©´ ë¹„ì§‘ì¤‘ ìƒíƒœ"
                            ],
                            range=["green", "blue", "orange", "red"]
                        )),
                        tooltip=["Time", "State"]
                    ).properties(height=150)
                    st.altair_chart(focus_chart, use_container_width=True)

# =================== ìë™ ë°˜ë³µ ===================
if st.session_state.running:
    time.sleep(0.1)
    st.rerun()
